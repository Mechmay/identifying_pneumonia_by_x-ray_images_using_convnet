{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chest_x-ray_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPU06huX430/4P+q72HZza"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "335z1S2Yb9HP",
        "outputId": "ddeca2c2-b8ac-4f15-b3ef-1d447b3618be"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJnjBuQVc2rC"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Colab_Notebooks/Deep Learning/Build deep learning models with tensorflow/Image Classification/data/train'\r\n",
        "validation_data_dir = '/content/drive/MyDrive/Colab_Notebooks/Deep Learning/Build deep learning models with tensorflow/Image Classification/data/test'\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLtEtZd1R37k",
        "outputId": "49d2fb84-0181-4d27-e8a9-9fdb71884572"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "# Data augmentation and prerocessing \r\n",
        "print(\"\\nLoading training data...\")\r\n",
        "\r\n",
        "training_data_generator = ImageDataGenerator(\r\n",
        "        rescale=1./255,\r\n",
        "        zoom_range=0.2,\r\n",
        "        rotation_range=15,\r\n",
        "        width_shift_range=0.05,\r\n",
        "        height_shift_range=0.05)\r\n",
        "\r\n",
        "training_iterator = training_data_generator.flow_from_directory(train_data_dir,class_mode='categorical',color_mode='grayscale',batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\nLoading validation data...\")\r\n",
        "\r\n",
        "#1) Create validation_data_generator, an ImageDataGenerator that just performs pixel normalization:\r\n",
        "\r\n",
        "\r\n",
        "validation_data_generator = ImageDataGenerator(rescale = 1./255)\r\n",
        "#2) Use validation_data_generator.flow_from_directory(...) to load the validation data from the 'data/test' folder:\r\n",
        "\r\n",
        "validation_iterator = validation_data_generator.flow_from_directory(validation_data_dir, class_mode = 'categorical', color_mode = 'grayscale', batch_size = BATCH_SIZE)\r\n",
        "\r\n",
        "print(\"\\nBuilding model...\")\r\n",
        "\r\n",
        "#Creating the model, with convolutional and max pooling layers:\r\n",
        "\r\n",
        "model = tf.keras.Sequential()\r\n",
        "# Our input feature map is 256x256x1: 256x256 for the image pixels, and 1 for\r\n",
        "# the color channel: grayscale\r\n",
        "model.add(tf.keras.Input(shape=(256, 256, 1)))\r\n",
        "\r\n",
        "# First convolution extracts 2 filters that are 5x5\r\n",
        "# Convolution is followed by max-pooling layer with a 5x5 window\r\n",
        "model.add(tf.keras.layers.Conv2D(2, 5, strides=3, activation=\"relu\")) \r\n",
        "model.add(tf.keras.layers.MaxPooling2D(\r\n",
        "    pool_size=(5, 5), strides=(5,5)))\r\n",
        "\r\n",
        "# Second convolution extracts 4 filters that are 3x3\r\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\r\n",
        "model.add(tf.keras.layers.Conv2D(4, 3, strides=1, activation=\"relu\")) \r\n",
        "model.add(tf.keras.layers.MaxPooling2D(\r\n",
        "    pool_size=(2,2), strides=(2,2)))\r\n",
        "\r\n",
        "# Flatten feature map to a 1-dim tensor\r\n",
        "model.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "model.add(tf.keras.layers.Dropout(0.2))\r\n",
        "\r\n",
        "# Create output layer with a single node and softmax activation\r\n",
        "model.add(tf.keras.layers.Dense(2,activation=\"softmax\"))\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\nCompiling model...\")\r\n",
        "\r\n",
        "#3) Compile the model with an Adam optimizer, Categorical Cross Entropy Loss, and Accuracy and AUC metrics:\r\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.005)\r\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "model.compile(\r\n",
        "    optimizer=opt,\r\n",
        "    loss=loss,\r\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\nTraining model...\")\r\n",
        "\r\n",
        "#4) train and validate model for 5 epochs:\r\n",
        "\r\n",
        "model.fit(\r\n",
        "        training_iterator,\r\n",
        "        steps_per_epoch=training_iterator.samples/BATCH_SIZE,\r\n",
        "        epochs=5,\r\n",
        "        validation_data=validation_iterator,\r\n",
        "        validation_steps=validation_iterator.samples/BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading training data...\n",
            "Found 5232 images belonging to 2 classes.\n",
            "\n",
            "Loading validation data...\n",
            "Found 624 images belonging to 2 classes.\n",
            "\n",
            "Building model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 84, 84, 2)         52        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 2)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 4)         76        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 4)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 394       \n",
            "=================================================================\n",
            "Total params: 522\n",
            "Trainable params: 522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Compiling model...\n",
            "\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "327/327 [==============================] - 1504s 5s/step - loss: 0.5838 - categorical_accuracy: 0.7306 - auc: 0.7502 - val_loss: 0.5272 - val_categorical_accuracy: 0.7115 - val_auc: 0.8255\n",
            "Epoch 2/5\n",
            "327/327 [==============================] - 74s 227ms/step - loss: 0.3797 - categorical_accuracy: 0.8394 - auc: 0.9113 - val_loss: 0.3465 - val_categorical_accuracy: 0.8462 - val_auc: 0.9280\n",
            "Epoch 3/5\n",
            "327/327 [==============================] - 74s 226ms/step - loss: 0.3148 - categorical_accuracy: 0.8682 - auc: 0.9412 - val_loss: 0.4016 - val_categorical_accuracy: 0.8221 - val_auc: 0.9034\n",
            "Epoch 4/5\n",
            "327/327 [==============================] - 73s 225ms/step - loss: 0.2884 - categorical_accuracy: 0.8781 - auc: 0.9500 - val_loss: 0.3812 - val_categorical_accuracy: 0.8189 - val_auc: 0.9119\n",
            "Epoch 5/5\n",
            "327/327 [==============================] - 73s 224ms/step - loss: 0.2916 - categorical_accuracy: 0.8823 - auc: 0.9479 - val_loss: 0.3161 - val_categorical_accuracy: 0.8622 - val_auc: 0.9389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6dbb6fa828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}